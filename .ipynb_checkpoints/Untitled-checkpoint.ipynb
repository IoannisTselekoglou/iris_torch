{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a178dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e900c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create custom data class\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,low_idx,high_idx):\n",
    "        self.data = pd.read_csv(\"./IRIS.csv.xls\", sep=\",\", skiprows=range(low_idx,high_idx), header=1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sepal_length = torch.tensor(self.data.iloc[idx, 0])\n",
    "        sepal_width = self.data.iloc[idx, 1]\n",
    "        petal_length = self.data.iloc[idx, 2]\n",
    "        petal_width = self.data.iloc[idx, 3] \n",
    "        label = self.data.iloc[idx, 4]\n",
    "        \n",
    "        tensor_data = torch.tensor([sepal_length,sepal_width,sepal_width,sepal_width],dtype=torch.float32)\n",
    "        \n",
    "        return tensor_data , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48179a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just my afwull way to seperate training and testing dataset\n",
    "# 80% training , 20% Test\n",
    "\n",
    "train_dataset = CustomDataset(120,149)\n",
    "test_dataset = CustomDataset(1,120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2505e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train_dataloader and test_dataloader\n",
    "# 80% for training, 20% of data for testing -> 149*0.8 = 119.2 -> 120 , 29\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True) \n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6c5883ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 inputs and 3  outputs \n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_stack =  nn.Sequential(\n",
    "         nn.Linear(4,128),\n",
    "         nn.ReLU(),\n",
    "         nn.Linear(128,64),\n",
    "         nn.ReLU(),\n",
    "         nn.Linear(64,3),\n",
    "         )\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ae5c52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map labels into tensor of shape [1, 0, 0]\n",
    "def transform_label(label_data):\n",
    "    data = []\n",
    "    for i in label_data:\n",
    "        if i == \"Iris-setosa\":\n",
    "            data.append(torch.tensor([1,0,0], dtype=torch.float32))\n",
    "        elif i == \"Iris-versicolor\": \n",
    "            data.append(torch.tensor([0,1,0], dtype=torch.float32))\n",
    "        else:\n",
    "            data.append(torch.tensor([0,0,1], dtype=torch.float32))\n",
    "    return torch.stack(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "650fee92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 4]), torch.Size([10, 3]), torch.float32, torch.float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_labels, X_train = next(iter(train_loader))\n",
    "X_train, train_labels = next(iter(train_loader))\n",
    "train_labels = transform_label(train_labels)\n",
    "X_train.shape, train_labels.shape, X_train.dtype, train_labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ec8e71ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.8000, 3.4000, 3.4000, 3.4000],\n",
       "        [5.4000, 3.4000, 3.4000, 3.4000],\n",
       "        [6.4000, 2.9000, 2.9000, 2.9000],\n",
       "        [7.2000, 3.6000, 3.6000, 3.6000],\n",
       "        [5.0000, 3.0000, 3.0000, 3.0000],\n",
       "        [6.1000, 2.8000, 2.8000, 2.8000],\n",
       "        [7.6000, 3.0000, 3.0000, 3.0000],\n",
       "        [5.0000, 3.2000, 3.2000, 3.2000],\n",
       "        [5.0000, 3.4000, 3.4000, 3.4000],\n",
       "        [7.7000, 2.6000, 2.6000, 2.6000]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "73605888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8edbb367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "lr = 0.01\n",
    "model = NeuralNetwork()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "#Weights are by default torch.32 not 64 --> error message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f80d9161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0, l=0.32698124647140503\n",
      " 10, l=0.6393840909004211\n",
      " 1, l=0.5648658275604248\n",
      " 11, l=0.36411982774734497\n",
      " 2, l=0.16015702486038208\n",
      " 12, l=0.20043572783470154\n",
      " 3, l=0.2897256016731262\n",
      " 13, l=0.45683664083480835\n",
      " 4, l=0.36841681599617004\n",
      " 14, l=0.0644836276769638\n",
      " 5, l=0.2726799547672272\n",
      " 15, l=0.3511088490486145\n",
      " 6, l=0.4158879220485687\n",
      " 16, l=0.3966699242591858\n",
      " 7, l=0.37308669090270996\n",
      " 17, l=0.6485604047775269\n",
      " 8, l=0.44491273164749146\n",
      " 18, l=0.276479035615921\n",
      " 9, l=0.2629351317882538\n",
      " 19, l=0.16783037781715393\n",
      " 10, l=0.3404849171638489\n",
      " 20, l=0.38651254773139954\n",
      " 11, l=0.44737544655799866\n",
      " 21, l=0.2695297598838806\n",
      " 12, l=0.7120384573936462\n",
      " 22, l=0.21662767231464386\n",
      " 13, l=0.282347708940506\n",
      " 23, l=0.4232925772666931\n",
      " 14, l=0.385120153427124\n",
      " 24, l=0.40164265036582947\n",
      " 15, l=0.12026827037334442\n",
      " 25, l=0.26520708203315735\n",
      " 16, l=0.35582318902015686\n",
      " 26, l=0.257016122341156\n",
      " 17, l=0.5732334852218628\n",
      " 27, l=0.5283920168876648\n",
      " 18, l=0.26541566848754883\n",
      " 28, l=0.22972874343395233\n",
      " 19, l=0.30231907963752747\n",
      " 29, l=0.21463993191719055\n",
      " 20, l=0.45117896795272827\n",
      " 30, l=0.16348807513713837\n",
      " 21, l=0.3282166123390198\n",
      " 31, l=0.22245192527770996\n",
      " 22, l=0.10542148351669312\n",
      " 32, l=0.44051533937454224\n",
      " 23, l=0.3827838599681854\n",
      " 33, l=0.384924054145813\n",
      " 24, l=0.1409820020198822\n",
      " 34, l=0.4954954981803894\n",
      " 25, l=0.32865485548973083\n",
      " 35, l=0.5135975480079651\n",
      " 26, l=0.2937954366207123\n",
      " 36, l=0.39537301659584045\n",
      " 27, l=0.30300015211105347\n",
      " 37, l=0.45806828141212463\n",
      " 28, l=0.4770638346672058\n",
      " 38, l=0.17815856635570526\n",
      " 29, l=0.25107601284980774\n",
      " 39, l=0.12931692600250244\n",
      " 30, l=0.10125569254159927\n",
      " 40, l=0.5405663251876831\n",
      " 31, l=0.54706871509552\n",
      " 41, l=0.1691896617412567\n",
      " 32, l=0.2448073923587799\n",
      " 42, l=0.29911941289901733\n",
      " 33, l=0.31786343455314636\n",
      " 43, l=0.35675543546676636\n",
      " 34, l=0.23065021634101868\n",
      " 44, l=0.42945265769958496\n",
      " 35, l=0.265494704246521\n",
      " 45, l=0.28919702768325806\n",
      " 36, l=0.3240543603897095\n",
      " 46, l=0.4135679602622986\n",
      " 37, l=0.2986716628074646\n",
      " 47, l=0.30778056383132935\n",
      " 38, l=0.5588012933731079\n",
      " 48, l=0.43438830971717834\n",
      " 39, l=0.19393499195575714\n",
      " 49, l=0.3549017012119293\n",
      " 40, l=0.24347420036792755\n",
      " 50, l=0.32344067096710205\n",
      " 41, l=0.40965136885643005\n",
      " 51, l=0.518182635307312\n",
      " 42, l=0.44790324568748474\n",
      " 52, l=0.2820853292942047\n",
      " 43, l=0.542457103729248\n",
      " 53, l=0.2354448288679123\n",
      " 44, l=0.4331091046333313\n",
      " 54, l=0.34847912192344666\n",
      " 45, l=0.25284343957901\n",
      " 55, l=0.31228959560394287\n",
      " 46, l=0.14955846965312958\n",
      " 56, l=0.32544389367103577\n",
      " 47, l=0.39706164598464966\n",
      " 57, l=0.25419318675994873\n",
      " 48, l=0.6323591470718384\n",
      " 58, l=0.5273822546005249\n",
      " 49, l=0.383944034576416\n",
      " 59, l=0.35031765699386597\n",
      " 50, l=0.568070113658905\n",
      " 60, l=0.4010806083679199\n",
      " 51, l=0.37548011541366577\n",
      " 61, l=0.401589959859848\n",
      " 52, l=0.21081331372261047\n",
      " 62, l=0.1577020287513733\n",
      " 53, l=0.19963422417640686\n",
      " 63, l=0.7580922842025757\n",
      " 54, l=0.19923463463783264\n",
      " 64, l=0.3809962570667267\n",
      " 55, l=0.1828279197216034\n",
      " 65, l=0.4753643870353699\n",
      " 56, l=0.16848082840442657\n",
      " 66, l=0.22615495324134827\n",
      " 57, l=0.21708235144615173\n",
      " 67, l=0.054646484553813934\n",
      " 58, l=0.4049013555049896\n",
      " 68, l=0.14879286289215088\n",
      " 59, l=0.12388875335454941\n",
      " 69, l=0.48797568678855896\n",
      " 60, l=0.10966862738132477\n",
      " 70, l=0.4361797869205475\n",
      " 61, l=0.3611010015010834\n",
      " 71, l=0.2558431923389435\n",
      " 62, l=0.3328517973423004\n",
      " 72, l=0.26416507363319397\n",
      " 63, l=0.32954055070877075\n",
      " 73, l=0.2585112452507019\n",
      " 64, l=0.8510896563529968\n",
      " 74, l=0.23941493034362793\n",
      " 65, l=0.32421594858169556\n",
      " 75, l=0.4034082293510437\n",
      " 66, l=0.4892188608646393\n",
      " 76, l=0.14644402265548706\n",
      " 67, l=0.39470285177230835\n",
      " 77, l=0.13653108477592468\n",
      " 68, l=0.3948931396007538\n",
      " 78, l=0.211748868227005\n",
      " 69, l=0.28006693720817566\n",
      " 79, l=0.2977232336997986\n",
      " 70, l=0.2556387484073639\n",
      " 80, l=0.615303099155426\n",
      " 71, l=0.3773272931575775\n",
      " 81, l=0.35856398940086365\n",
      " 72, l=0.3217672109603882\n",
      " 82, l=0.5485249161720276\n",
      " 73, l=0.7286814451217651\n",
      " 83, l=0.2449425458908081\n",
      " 74, l=0.5459271669387817\n",
      " 84, l=0.44862619042396545\n",
      " 75, l=0.22185957431793213\n",
      " 85, l=0.49000492691993713\n",
      " 76, l=0.09927701950073242\n",
      " 86, l=0.3410934507846832\n",
      " 77, l=0.33666083216667175\n",
      " 87, l=0.285266637802124\n",
      " 78, l=0.36100536584854126\n",
      " 88, l=0.5184510350227356\n",
      " 79, l=0.40264296531677246\n",
      " 89, l=0.1998625099658966\n",
      " 80, l=0.28281012177467346\n",
      " 90, l=0.5473202466964722\n",
      " 81, l=0.3063872456550598\n",
      " 91, l=0.059560708701610565\n",
      " 82, l=0.5284237861633301\n",
      " 92, l=0.16851136088371277\n",
      " 83, l=0.4948059022426605\n",
      " 93, l=0.14721225202083588\n",
      " 84, l=0.11492286622524261\n",
      " 94, l=0.3761344850063324\n",
      " 85, l=0.2881278395652771\n",
      " 95, l=0.3141789436340332\n",
      " 86, l=0.4224579334259033\n",
      " 96, l=0.29127365350723267\n",
      " 87, l=0.22078299522399902\n",
      " 97, l=0.36647430062294006\n",
      " 88, l=0.27735552191734314\n",
      " 98, l=0.20400314033031464\n",
      " 89, l=0.1822337806224823\n",
      " 99, l=0.2870611548423767\n",
      " 90, l=0.22863130271434784\n",
      " 100, l=0.3405410647392273\n",
      " 91, l=0.20054027438163757\n",
      " 101, l=0.3424094319343567\n",
      " 92, l=0.1591511070728302\n",
      " 102, l=0.5826190114021301\n",
      " 93, l=0.28005877137184143\n",
      " 103, l=0.558121383190155\n",
      " 94, l=0.34307825565338135\n",
      " 104, l=0.29477494955062866\n",
      " 95, l=0.33565646409988403\n",
      " 105, l=0.30532577633857727\n",
      " 96, l=0.2710232734680176\n",
      " 106, l=0.3437175154685974\n",
      " 97, l=0.3078119158744812\n",
      " 107, l=0.1918649971485138\n",
      " 98, l=0.3044871389865875\n",
      " 108, l=0.38688310980796814\n",
      " 99, l=0.3146583139896393\n",
      " 109, l=0.38335689902305603\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(100):\n",
    "    #forward pass and loss\n",
    "    #test_labels, X_test = next(iter(test_loader))\n",
    "    for i,(inputs, labels) in enumerate(train_loader):\n",
    "        out = model(inputs)\n",
    "        train_labels = transform_label(labels)\n",
    "        l = loss(out, train_labels)\n",
    "        #backward pass\n",
    "        l.backward()\n",
    "        #update weights\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\" {epochs+i}, l={l.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5657a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = torch.tensor([4.9,3.1,1.5,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1550545c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.1777,  1.3487, -0.8711], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9ecaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dc3b13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n",
    "X_test, test_labels = next(iter(train_loader))\n",
    "test_labels = transform_label(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d6085928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.2960, -3.8560, -6.4374],\n",
       "        [-7.4541,  1.3615,  0.2566],\n",
       "        [ 7.3516, -3.9103, -6.4162],\n",
       "        [-9.5299,  1.4385,  0.7121],\n",
       "        [ 7.2713, -4.0111, -6.4982],\n",
       "        [-7.1527,  1.3942,  0.1275],\n",
       "        [-7.1527,  1.3942,  0.1275],\n",
       "        [ 7.3538, -4.6641, -6.9892],\n",
       "        [ 0.6386,  0.1537, -1.9625],\n",
       "        [ 9.2446, -5.7586, -8.0928]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "286d7de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41aac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
